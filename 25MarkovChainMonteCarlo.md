# MCMC
## 一、简介
MCMC，全称Markov chain Monte Carlo，马尔可夫链蒙特卡洛，是一种使用随机抽样来近似复杂积分的方法，在机器学习，深度学习以及自然语言处理等领域都有广泛的应用，是很多复杂算法求解的基础。MCMC由马尔可夫链和蒙特卡洛积分两部分组成。核心思想是通过构造马尔可夫链从想做积分的分布中抽样，然后利用蒙特卡洛积分来近似求解积分。  
* 解决问题：使用随机抽样来近似复杂积分  
* 核心思想：构造马尔可夫链从目标积分的分布中抽样，然后利用蒙特卡洛积分来近似求解   
* 组成部分：蒙特卡洛积分（Monte Carlo integration）、马尔可夫链（Markov chain）  
本文将按照下面的思路介绍MCMC：
1. 蒙特卡洛积分——对应第二小节
2. 马尔可夫链——对于第三小节
3. MCMC采样原理——对应第四小节
4. MCMC采样具体方法——对应第五小节

## 二、蒙特卡洛积分（Monte Carlo integration）
最早的蒙特卡洛方法都是为了求解一些不太好求解的求和或者积分问题。比如积分：  
$$\theta =\int_a^bf(x)dx$$
如果不知道$f(x)$的原函数，那么这个积分就比较难求解。  
常用的思路是通过模拟求解近似值。假设函数图像如下:  
【图像】
则一个简单的近似求解方法是在$[a,b]$之间随机的采样一个点。比如$x_0$，然后用$f(x_0)$代表在$[a,b]$区间上所有的$f(x)$的值。那么定积分的近似求解为:  
$$(b-a)f(x_0)$$
然而选择一个数来近似太过粗糙。我们可以采样$[a,b]$区间的n个值：$x_0,x_1,...x_{n-1}$,用它们的均值来代表$[a,b]$区间上所有的$f(x)$的值。这样上面定积分的近似求解为:  
$$\frac{b-a}n\sum_{i=0}^{n-1}f(x_i)$$
虽然选取多个点的方法可以更好地求解出近似解，但是它隐含了一个假定，即$x$在$[a,b]$之间是均匀分布的。然而绝大部分时候，$x$在$[a,b]$之间不是均匀分布的。如果仍然采用上面的方法，模拟求出的结果很可能和真实值相差甚远。　
为了解决这个问题，即引入蒙特卡洛方法。蒙特卡洛利用了概率分布函数这一特征。假设$x$在$[a,b]$的概率分布函数$p(x)$，那么我们的定积分求和可以这样进行：  
$$\theta = \int_a^bf(x)dx=\int_a^b\frac{f(x)}{p(x)}p(x)dx\approx \frac{1}{n}\sum_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}$$
上式最右边的这个形式就是蒙特卡洛方法的一般形式。（这里是连续函数形式，离散情况一样成立)  
比如，假设$x$在$[a,b]$上是均匀分布，即$p(x_i)=\frac{1}{(b-a)}$。那么利用蒙特卡洛积分求解  
$$\int_a^bf(x)dx=\frac{1}{n}\sum_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}=\frac{(b-a)}{n}\sum_{i=0}^{n-1}f(x_i)$$
然而，虽然蒙特卡洛积分能够较好地求解积分问题，它在应用上仍然存在两个缺点：  
* 面对一些不常见的分布的时候，在很多时候很难获取它的概率分布函数，也很难得到相应概率分布的样本集。
* 同时，对于一些高维的复杂非常见分布，其先验和后验分布均是高维的。这种情况通常被描述为维度诅咒（curse of dimensionality）。这就意味着当维度增加时，空间$x_j$的体积增加得非常之快（以指数增加），可用的数据变得稀疏，数据的统计意义下降。仅仅基于蒙特卡洛的概率分布采样方法很难获取所需的样本集。  

因此，要想将蒙特卡罗方法作为一个通用的采样模拟求积分的方法，就需要从分布中抽样，得到各种复杂概率分布的对应的采样样本集$x^{(1)},x^{(2)},...,x^{(n)}$。这时MCMC引入了马尔可夫链来解决这个需求。  
 
## 三、马尔可夫链（Markov chain）
蒙特卡洛积分是利用有关分布的随机抽样来近似积分的一种有利方法，但从有关概率分布中抽样很困难或者无法直接做到，因此MCMC加入了马尔可夫链。马尔可夫链是一种序贯模型，它以概率的方式从一种状态转移到另一种状态，其中链所采取的下一个状态取决于以前的状态（即马尔可夫性）。如果马尔可夫链构造得当并运行很长时间，那么它也将从目标概率分布中提取样本的状态这也就是马氏链能够以较小的样本得到好的近似的根本。  
 
MCMC使用马尔可夫链机制生成样本$x^{(i)}$，这种构造是为了使链花费更多时间在最重要的地方。特别的是，它使样本$x^{(i)}$模拟从目标分布$p(x)$中提取样本，当然，用MCMC不能直接从$p(x)$中提取样本，但可以估计$p(x)$到一个标准化常数的程度。  

**马尔可夫链的定义如下：**  
假设我们在有限空间$\chi = {x_1,x_2,...,x_s}$上引入马尔可夫链，令$x^{(i)}$为马尔可夫链的第$i$个状态，这里$x^{(i)}\in \chi$只能由$s$个离散值。满足下面性质的随机过程$x^{(i)}$被称为马尔可夫链：  
$$p(x^{(i)}|x^{(i-1)},x^{(i-2)},...x^{(1)})=p(x^{(i)}|x^{(i-1)}), \forall i$$  
式中的$p(x^{(i)}|x^{(i-1)})$称为从状态x^{(i-1)到状态(x^{(i)的转移概率。上式意味着随机过程处于某状态的概率仅依赖于前一个状态，与之前的历史无关，这就是马尔可夫链的马尔可夫性。  
**下面介绍马尔可夫链中的5个概念：**  
1. <b>时齐</b>  
如果对于任意两个状态$x_i,x_j \in \chi$，$s \times s$矩阵$\pmb P \equiv [p_{ij}]=[p(x^{(k)}|x^{(k-1)}=x_i)]$对所有$k$保持不变，而且$\sum_i P_{ij}=1$，则称马尔可夫链是时齐的。
2. <b>转移概率和转移概率矩阵</b>  
转移概率是马尔可夫链中的重要概念，若马氏链分为m个状态组成。从任意一个状态出发，经过任意一次转移，必然出现状态$1,2,...m$中的一个，这种状态之间的转移称为转移概率。   
其表达式为  $$P_{ij}(m,m+n)=P(X_{m+n}=j|X_m=i)$$
称$p_{ij}(m,m+n)$为链在$m$时刻处于$i$状态,再经$n$步转移到$j$状态的转移概率,简称$n$步转移概率。  
如果以$p_{ij}(m,m+n)$ 作为矩阵$\pmb P(m,m+n)$的第$i$行第$j$列元素,则$\pmb P(m,m+n)$称为马氏链的$n$步转移阵。值得注意的是,当$n=1$时，一步转移概率为$p_{ij}(m,m+1)$。其组成的是一步转移概率矩阵，记为$\pmb P_{ij}(m)$。  
    1. 转移概率性质  
    * 对$\forall m,n,i,j$，有$p_{ij}(m,m+n)\geq 0$
    * 对$\forall m,n,i$，有$\sum_{j\in E}p_{ij}(m,m+n)=1$
    2. 一步转移概率矩阵性质
    * $0\leq \pmb P_{ij}(m) \geq 1,i\in I$
    * $\sum_{j\in I}\pmb P_{ij}(m)\leq 1$
    3. 转移矩阵条件  
    为了保证初始概率分布不影响后续稳定后的概率，转移矩阵需要满足以下两个条件：
    * 不可约性（irreducibility）  
    即非负性，从任何状态出发访问马尔可夫链的任何其他状态的概率都是正的。同时也意味着，转移矩阵不能再简化为更小的矩阵。  
    * 非周期性（aperiodicity）  
    马氏链不能被困在循环中，即需要马氏链是非周期性的。  
    假设有一个状态$x_i$，它经历$t$步之后回到自身状态的转移概率为$\pmb P_{ii}^t$，则周期为：  $$k=gcd(n|\pmb P_{ii}^n>0)$$
    式子中，$gcd$表示最大公约数。如果$k=1$，则状态$x_i$称为非周期性的。  
    如果每个状态都是非周期性的，那么马尔可夫链是非周期性的，一个不可约的马尔可夫链需要是非周期性的。
 
3. 平稳概率(stationary distribution)  
对于任意初始分布$\pmb \pi_0 = (\pi_1^{(0)},\pi_2^{(0)},...\pi_s^{(0)})$，在$t$次转换之后在各个状态的概率为向量  $$\pmb \pi_0\overbrace{PP...P}^t = \pmb \pi_0P^t$$
很容易验证，当$t$很大时，概率向量$\pi_0P^t$收敛到一个稳定的值$\pi$，而且该值和初始概率$\pi_0$无关，即  $$\lim_{t\rightarrow \infty}\pmb \pi_0P^t = \pmb \pi$$
乘积矩阵$\pmb P^t$的元素$P_{ij}^t$为从状态$x_i$经过$x$步转移到状态$x_j$的概率，显然有如下关系式：  $$\pmb \pi = \pmb \pi \pmb P$$
概率$\pmb \pi$称为平稳概率（stationary distribution或者equilibrium distribution），求解平稳概率即是求解$\pmb P^\mathsf{T}$特征值问题，这也是转移矩阵必须满足两大条件的一个原因。  
R的伪代码如下：
    ```R 
    状态转移矩阵P = matrix(矩阵数据)
    初始概率p0 = c(数据)
    p1 = p0  # 进行到下一步
    for(i in 1:迭代次数)
    P1 = P1%*%P
    P1  # 返回结果
    ```
    Python的伪代码如下：  
    ```Python
    状态转移矩阵A=[数据]
    阶段n步=状态转移矩阵A
    阶段n1步=np.dot(状态转移矩阵A,状态转移矩阵A)
    while not (阶段n步 == 阶段n1步).all():
        阶段n步 = 阶段n1步
        阶段n1步 = np.dot(阶段n1步,状态转移矩阵A)
    print(阶段n步)
    ```
    结合转移矩阵的非周期性和平稳概率，可以发现，如果从状态$x_i$总是可以到达$x_j$的概率为$\pi_j$对于所有$j$成立，或当$n\rightarrow \infty$  $$P_{ij}^n \rightarrow \pi_j,\forall j$$
    那么$\pmb \pi = (\pi_1,\pi_2,...\pi_s)$为不变的。除此之外，如果不可约的链有一个平稳的分布，那么该平衡分布是唯一的。
4. 遍历原理（erigodic theorem）  
所谓遍历原理，即指如果马尔可夫链  $$x^{(1)},x^{(2)},...x^{(n)}\sim \pmb \pi$$
是非周期性和不可约的，而且$\pmb \pi$是平稳分布，那么，当$n\rightarrow \infty$时，有  $$\frac{1}{n} \sum_n^{t=1}h(x^{(t)}) \rightarrow E_{\pmb \pi}[h(x)]=\int h(\pmb x)\pmb\pi(\pmb x)d\pmb x$$  
5. 细致平稳条件（detailed balance condition）  
如果非周期马氏链的转移矩阵$\pmb P$和分布$\pi(x)$满足$$\pi(i)\pmb P_{ij}=\pi(j)\pmb P_{ij}\qquad for all\, i,j$$
$\pi(x)$是马氏链的平稳分布，上式被称为细致平稳条件。  
基于 


## 四、MCMC采样原理
## 五、MCMC采样具体方法
### 方法综述  
对于贝叶斯推断，MCMC模拟一个自选初始点$\theta^{(0)}$的离散时间马尔可夫链，产生一串相依的随机变量${\{\theta^{(i)}}\}_{i=1}^M$，有近似分布  $$p(\theta^{(i)})\approx p(\theta |x)$$
由于马尔可夫性，$\theta^{(i)}$的分布仅仅和$\theta^{(i-1)}$有关  
MCMC在状态空间$\theta\in\Theta$产生了一个马尔可夫链${\{\theta^{(1)},\theta^{(2)},...\theta^{(M)}}\}$，其每个样本都假定来自稳定分布$p(\theta|x)$，即后验分布。  
使用马尔可夫链从特定的目标分布中进行抽样，关键是必须设计合适的转移矩阵（算子），以便生成的链达到与目标分布相匹配的稳定分布，这也是所有MCMC方法的核心目标。
#### Gibb抽样   
 **理论**  
已发现在许多多维问题中有用的特定马尔可夫链算法是Gibbs采样器，也称为altering conditional sampling。  
根据《Bayesian Data Analysis》，Gibbo抽样由$\theta$子向量定义。假设参数向量$θ$已被划分为$d$个分量或子向量，$\theta=(\theta_1,...\theta_d)$。Gibbs采样器的每次迭代循环都遍历$\theta$的子向量，根据所有其他子集的值绘制每个子集。
在每次迭代时，选择$θ$的$d$个子向量的顺序，然后，每个$\theta_j$从给定所有$\theta$的其他分量的条件分布$$p(\theta_j|\theta_{-j},y)$$中采样。  
其中$\theta_{-j}$表示$\theta$除了$\theta_j$外的所有分量，公式如下：  $$\theta_{-j}=(\theta_1,...,\theta_{j-1},\theta_{j+1},...,\theta_d)$$
因此，每个子向量$\theta_j$依据$θ$的其他分量的最新值更新。
简单来说，

#### Metropolis算法

#### M-H算法
#### Hamiltonmian蒙特卡罗算法
## 六、参考文献
