# 概率图模型

## Probabilistic Graphical Models

### 一、基础知识

假设我们的观测对象是高维随机变量$(x_1,x_2,...,x_p)$，对于这样的一个高维随机变量而言，在实际操作过程中，我们往往需要知道的是它的边缘概率$p(x_i)$，以及条件概率$p(x_j|x_i)$。

首先，我们来看下对于高维随机变量（下面以二维为例），两个基本运算法则：

加法法则：$p(x_1)=\int p(x_1,x_2)dx_2$

乘法法则：$p(x_1,x_2)=p(x_1|x_2)p(x_2)=p(x_2|x_1)p(x_1)$

根据两个基本法则可以推出两个常用的法则：

链式法则：$p(x_1,x_2,...,x_p)=p(x_1)\prod_{a}^{b}p(x_i|x_1,x_2,...x_{i-1})$

贝叶斯法则：$p(x_2|x_1)=\frac{p(x_2,x_1)}{\int p(x_2,x_1)x_2}=\frac{p(x_1|x_2)p(x_2)}{\int p(x_2,x_1)x_2}=\frac{p(x_1|x_2)p(x_2)}{\int p(x_1|x_2)p(x_2)x_2}$

### 二、概率图模型的基本概念

**概率图模型（Probabilistic Graphical Model，PGM）**，简称图模型（Graphical Model，GM），是指一种用图结构来描述多元随机变量之间**条件独立性**的概率模型，从而给研究高维空间的概率模型带来了很大的便捷性。

#### 概率图模型的三个基本问题

##### 1.表示问题：对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。

##### 2.学习问题：概率图模型的参数学习，即参数估计问题

##### 3.推断问题：在已知部分变量时，计算其他变量的条件概率分布

### 三、概率图模型的表示方式：有向图/无向图

概率图模型的表示是指用图结构来描述变量之间的依赖关系，研究如何利用概率网络中的独立性来简化联合概率分布的方法表示。常见的概率图模型可以分为两类：**有向图模型和无向图模型**。

有向图模型使用**有向非循环图（Directed Acyclic Graph，DAG）**来描述变量之间的关系。如果两个节点之间有连边，表示对应的两个变量为因果关系，即不存在其他变量使得这两个节点对应的变量条件独立。

有向图又称**贝叶斯网络**，从模型的条件独立性依赖的个数上看，可以分为单一模型和混合模型，单一模型条件依赖的集合就是单个元素，而混合模型条件依赖的集合则是多个元素。如果给模型加上时间概念，则可以有马尔科夫链和高斯过程等。从空间上，如果随机变量是连续的，则有如高斯贝叶斯网络这样的模型。混合模型加上时间序列，则有隐马尔科夫模型、卡尔曼滤波、粒子滤波等模型。

无向图模型使用无向图（Undirected Graph）来描述变量之间的关系。每条边代表两个变量之间有概率依赖关系，但是并不一定是因果关系。

==下图==给出了两个代表性图模型（有向图和无向图）的示例，分别表示了四个变量${X_1,X_2,X_3,X_4}$之间的依赖关系。图中带阴影的节点表示可观测到的变量，不带阴影的节点表示隐变量，连边表示两变量间的条件依赖关系。

##### 1.有向图模型

有向图模型（Directed Graphical Model），也称为贝叶斯网络（Bayesian Network）或信念网络（Belief Network，BN），是一类用有向图来描述随机向量概率分布的模型。常见的有向图模型：很多经典的机器学习模型可以使用有向图模型来描述，比如**朴素贝叶斯分类器**、**隐马尔可夫模型**、**深度信念网络等**。

贝叶斯网络：对于一个$K$维随机向量$X$和一个有 $K$个节点的有向非循环图$G$,$G$中的每个节点都对应一个随机变量，每个连接$e_{ij}$表示两个随机变量 $X_i$和$X_j$之间具有非独立的因果关系。令$X_{\pi k}$表示变量$X_k$的所有父节点变量集和，$P(X_k|X_{\pi k})$表示每个随机变量的局部条件概率分布（Local Conditional Probability Distribution）。如果$X$的联合概率分布可以分解为每个随机变量 $X_k$的局部条件概率的连乘形式，即
$$
p(x)=\prod_{k=1}^{K}p(x_k|x_{\pi k})
$$
那么$(G,K)$构成了一个贝叶斯网络。

贝叶斯网络模型的概率分解，在贝叶斯网络中，变量间存在如下四种关系：

（1）如果两个节点是直接连接的，它们肯定是非条件独立的，是直接因果关系。其中父节点是“因”，子节点是“果”。

（2）间接因果关系（head-to-tail），即==图（a）、图（b）==：当$X_2$已知时，$X_1$和$X_3$为条件独立，即$X_1\bot X_3|X_2$。

（3）共因关系（tail-to-tail），即==图（c）==：当$X_2$未知时，$X_1$和$X_3$是不独立的；当$X_2$已知时，$X_1$和$X_3$条件独立，即$X_1\bot X_3|X_2$。

（4）共果关系（head-to-head），即==图（d）==：当 $X_2$未知时，$X_1$和$X_3$是独立的；当 $X_2$已知时，$X_1$和$X_3$不独立。

##### 2.无向图模型

无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或马尔可夫网络（Markov Network），是一类用无向图来描述一组具有局部马尔可夫性质的随机向量$X$的联合概率分布的模型。常见的无向图模型有：**最大熵模型**、**条件随机场**、**玻尔兹曼机**、**受限玻尔兹曼机等**。

马尔可夫随机场：对于一个随机向量 $X=[X_1,X_2,...,X_k]^T$和一个有$K$个节点的无向图$G(\nu,\varepsilon)$ （可以存在循环），图 $G$中的节点$k$表示随机变量$X_k$，$1\leq k\leq K$。如果$(G,X)$满足局部马尔可夫性质，即一个变量 $X_k$在给定它的邻居的情况下独立于所有其他变量， $p(x_k|x_{\k})=p(x_k|x_{\aleph(k)})$其中$\aleph(k)$为变量$X_k$的邻居集合，$\k$为除$X_k$外其他变量的集合，那么$(G,X)$就构成了一个马尔可夫场。



### 四、学习：图结构的学习和参数的学习

图模型的学习可以分为两部分：一是网络结构学习，即寻找最优的网络结构;二是网络参数估计，即已知网络结构，估计每个条件概率分布的参数。

网络结构学习比较困难，一般是由领域专家来构建。本节只讨论在给定网络 结构条件下的参数估计问题。图模型的参数估计问题又分为不包含隐变量时的 参数估计问题和包含隐变量时的参数估计问题。

不含隐变量的参数估计：如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一般可以直接通过最大似然来进行估计。

含隐变量的参数估计：如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用EM算法进行参数估计。

### 五、推断：精确推断/近似推断

精确推断包括（变量消除法，信念传播算法），近似推断包括（环路信念传播，变分推断，采样法）

在已知部分变量时算其它变量的后验概率分布。在图模型中，推断（Inference）是指在观测到部分变量$e=\left\{e_1,e_2,...e_M\right\}$时，计算其他变量的某个子集 $q=\left\{q_1,q_2,...q_M\right\}$的条件概率$p(q|e)$。假设一个图模型中，除了变量$e$、$q$外，其余变量表示为$z$。根据贝叶斯公式有
$$
p(q｜e)=\frac{p(q,e)}{p(e)}\\=\frac{\sum_{z}p(q,e,z)}{\sum_{q,z}p(q,e,z)}
$$
因此，图模型的推断问题的关键为求任意一个变量子集的边际概率分布问题。 在图模型中，常用的推断算法可以分为精确推断算法和近似推断算法两类。





